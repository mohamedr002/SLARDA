{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import copy\n",
    "from scipy import stats\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided as ast\n",
    "import pdb\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme: \n",
    "- OPPORTUNITY Activity Recognition Data Set'. OPPORTUNITY is a dataset devised to benchmark human activity recognition algorithms. It comprises the readings of motion sensors recorded while users executed typical daily activities and includes several annotations of gestures and modes of locomotion (visit https://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition for further info)\n",
    "\n",
    "- We followed \"OrdÃ³Ã±ez, Francisco Javier, and Daniel Roggen. \"Deep convolutional and lstm recurrent neural networks for  multimodal wearable activity recognition.\" Sensors 16.1 (2016): 115.\": \n",
    "    - The missing values are replaced by linear interpolation\n",
    "    - Sensor reading for activity recognition of 4 different participants\n",
    "    - Data has two level of classes \n",
    "        - Locomotion: low level tasks 4 classes (we removed the null class) \n",
    "        - Gestures: High level classes 17 classes (we removed the null class)\n",
    "    - Data has 245 columns, we selected 113 channel following the opportunity Challenge\n",
    "    - Window length of 128 with overlapping of 50% following existing literature\n",
    "- The train test split is done according to the opportunity Challenge\n",
    "\n",
    "# Domain Adaptation Settings: \n",
    "- In our expirements, we aim to explore the cross-subjects performance. Each subject is considered as different domain. In each subject, we used the first 3 runs for training,  the fourth run for validation, and the fifth run for the testing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def select_columns_opp(data):\n",
    "    \"\"\"Selection of the 113 columns employed in the OPPORTUNITY challenge\n",
    "    :param data: numpy integer matrix\n",
    "        Sensor data (all features)\n",
    "    :return: numpy integer matrix\n",
    "        Selection of features\n",
    "    \"\"\"\n",
    "    features_delete = np.arange(46, 50)\n",
    "    features_delete = np.concatenate([features_delete, np.arange(59, 63)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(72, 76)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(85, 89)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(98, 102)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(134, 243)])\n",
    "    features_delete = np.concatenate([features_delete, np.arange(244, 249)])\n",
    "    return np.delete(data, features_delete, 1)\n",
    "\n",
    "\n",
    "def normalize(data, max_list, min_list):\n",
    "    \"\"\"Normalizes all sensor channels\n",
    "    :param data: numpy integer matrix\n",
    "        Sensor data\n",
    "    :param max_list: numpy integer array\n",
    "        Array containing maximums values for every one of the 113 sensor channels\n",
    "    :param min_list: numpy integer array\n",
    "        Array containing minimum values for every one of the 113 sensor channels\n",
    "    :return:\n",
    "        Normalized sensor data\n",
    "    \"\"\"\n",
    "    max_list, min_list = np.array(max_list), np.array(min_list)\n",
    "    diffs = max_list - min_list\n",
    "    for i in np.arange(data.shape[1]):\n",
    "        data[:, i] = (data[:, i]-min_list[i])/diffs[i]\n",
    "    #     Checking the boundaries\n",
    "    data[data > 1] = 0.99\n",
    "    data[data < 0] = 0.00\n",
    "    return data\n",
    "\n",
    "\n",
    "def divide_x_y(data, label):\n",
    "    \"\"\"Segments each sample into features and label\n",
    "    :param data: numpy integer matrix\n",
    "        Sensor data\n",
    "    :param label: string, ['gestures' (default), 'locomotion']\n",
    "        Type of activities to be recognized\n",
    "    :return: numpy integer matrix, numpy integer array\n",
    "        Features encapsulated into a matrix and labels as an array\n",
    "    \"\"\"\n",
    "\n",
    "    data_x = data[:, 1:114]\n",
    "    if label not in ['locomotion', 'gestures']:\n",
    "            raise RuntimeError(\"Invalid label: '%s'\" % label)\n",
    "    if label == 'locomotion':\n",
    "        data_y = data[:, 114]  # Locomotion label\n",
    "    elif label == 'gestures':\n",
    "        data_y = data[:, 115]  # Gestures label\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "\n",
    "def adjust_idx_labels(data_y, label):\n",
    "    \"\"\"Transforms original labels into the range [0, nb_labels-1]\n",
    "    :param data_y: numpy integer array\n",
    "        Sensor labels\n",
    "    :param label: string, ['gestures' (default), 'locomotion']\n",
    "        Type of activities to be recognized\n",
    "    :return: numpy integer array\n",
    "        Modified sensor labels\n",
    "    \"\"\"\n",
    "\n",
    "    if label == 'locomotion':  # Labels for locomotion are adjusted\n",
    "        data_y[data_y == 4] = 3\n",
    "        data_y[data_y == 5] = 4\n",
    "    elif label == 'gestures':  # Labels for gestures are adjusted\n",
    "        data_y[data_y == 406516] = 1\n",
    "        data_y[data_y == 406517] = 2\n",
    "        data_y[data_y == 404516] = 3\n",
    "        data_y[data_y == 404517] = 4\n",
    "        data_y[data_y == 406520] = 5\n",
    "        data_y[data_y == 404520] = 6\n",
    "        data_y[data_y == 406505] = 7\n",
    "        data_y[data_y == 404505] = 8\n",
    "        data_y[data_y == 406519] = 9\n",
    "        data_y[data_y == 404519] = 10\n",
    "        data_y[data_y == 406511] = 11\n",
    "        data_y[data_y == 404511] = 12\n",
    "        data_y[data_y == 406508] = 13\n",
    "        data_y[data_y == 404508] = 14\n",
    "        data_y[data_y == 408512] = 15\n",
    "        data_y[data_y == 407521] = 16\n",
    "        data_y[data_y == 405506] = 17\n",
    "    return data_y\n",
    "def process_dataset_file(data, label):\n",
    "    \"\"\"Function defined as a pipeline to process individual OPPORTUNITY files\n",
    "    :param data: numpy integer matrix\n",
    "        Matrix containing data samples (rows) for every sensor channel (column)\n",
    "    :param label: string, ['gestures' (default), 'locomotion']\n",
    "        Type of activities to be recognized\n",
    "    :return: numpy integer matrix, numy integer array\n",
    "        Processed sensor data, segmented into features (x) and labels (y)\n",
    "    \"\"\"\n",
    "\n",
    "    # Select correct columns\n",
    "    data = select_columns_opp(data)\n",
    "\n",
    "    # Colums are segmentd into features and labels\n",
    "    data_x, data_y =  divide_x_y(data, label)\n",
    "    data_y = adjust_idx_labels(data_y, label)\n",
    "    data_y = data_y.astype(int)\n",
    "\n",
    "    # Perform linear interpolation\n",
    "    data_x = np.array([Series(i).interpolate() for i in data_x.T]).T\n",
    "\n",
    "    # Remaining missing data are converted to zero\n",
    "    data_x[np.isnan(data_x)] = 0\n",
    "\n",
    "    # All sensor channels are normalized\n",
    "    data_x = normalize(data_x, NORM_MAX_THRESHOLDS, NORM_MIN_THRESHOLDS)\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "def norm_shape(shape):\n",
    "    '''\n",
    "    Normalize numpy array shapes so they're always expressed as a tuple,\n",
    "    even for one-dimensional shapes.\n",
    "\n",
    "    Parameters\n",
    "        shape - an int, or a tuple of ints\n",
    "\n",
    "    Returns\n",
    "        a shape tuple\n",
    "    '''\n",
    "    try:\n",
    "        i = int(shape)\n",
    "        return (i,)\n",
    "    except TypeError:\n",
    "        # shape was not a number\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        t = tuple(shape)\n",
    "        return t\n",
    "    except TypeError:\n",
    "        # shape was not iterable\n",
    "        pass\n",
    "\n",
    "    raise TypeError('shape must be an int, or a tuple of ints')\n",
    "\n",
    "def sliding_window(a,ws,ss = None,flatten = True):\n",
    "    '''\n",
    "    Return a sliding window over a in any number of dimensions\n",
    "\n",
    "    Parameters:\n",
    "        a  - an n-dimensional numpy array\n",
    "        ws - an int (a is 1D) or tuple (a is 2D or greater) representing the size\n",
    "             of each dimension of the window\n",
    "        ss - an int (a is 1D) or tuple (a is 2D or greater) representing the\n",
    "             amount to slide the window in each dimension. If not specified, it\n",
    "             defaults to ws.\n",
    "        flatten - if True, all slices are flattened, otherwise, there is an\n",
    "                  extra dimension for each dimension of the input.\n",
    "\n",
    "    Returns\n",
    "        an array containing each n-dimensional window from a\n",
    "    '''\n",
    "\n",
    "    if None is ss:\n",
    "        # ss was not provided. the windows will not overlap in any direction.\n",
    "        ss = ws\n",
    "    ws = norm_shape(ws)\n",
    "    ss = norm_shape(ss)\n",
    "\n",
    "    # convert ws, ss, and a.shape to numpy arrays so that we can do math in every\n",
    "    # dimension at once.\n",
    "    ws = np.array(ws)\n",
    "    ss = np.array(ss)\n",
    "    shape = np.array(a.shape)\n",
    "\n",
    "\n",
    "    # ensure that ws, ss, and a.shape all have the same number of dimensions\n",
    "    ls = [len(shape),len(ws),len(ss)]\n",
    "    if 1 != len(set(ls)):\n",
    "        raise ValueError(\\\n",
    "        'a.shape, ws and ss must all have the same length. They were %s' % str(ls))\n",
    "\n",
    "    # ensure that ws is smaller than a in every dimension\n",
    "    if np.any(ws > shape):\n",
    "        raise ValueError(\\\n",
    "        'ws cannot be larger than a in any dimension.\\\n",
    " a.shape was %s and ws was %s' % (str(a.shape),str(ws)))\n",
    "\n",
    "    # how many slices will there be in each dimension?\n",
    "    newshape = norm_shape(((shape - ws) // ss) + 1)\n",
    "    # the shape of the strided array will be the number of slices in each dimension\n",
    "    # plus the shape of the window (tuple addition)\n",
    "    newshape += norm_shape(ws)\n",
    "    # the strides tuple will be the array's strides multiplied by step size, plus\n",
    "    # the array's strides (tuple addition)\n",
    "    newstrides = norm_shape(np.array(a.strides) * ss) + a.strides\n",
    "    strided = ast(a,shape = newshape,strides = newstrides)\n",
    "    if not flatten:\n",
    "        return strided\n",
    "\n",
    "    # Collapse strided so that it has one more dimension than the window.  I.e.,\n",
    "    # the new array is a flat list of slices.\n",
    "    meat = len(ws) if ws.shape else 0\n",
    "    firstdim = (np.product(newshape[:-meat]),) if ws.shape else ()\n",
    "    dim = firstdim + (newshape[-meat:])\n",
    "\n",
    "    return strided.squeeze()\n",
    "\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "\n",
    "    \n",
    "def generate_data(window_size, step_size,  data_annotation, files, n_sensors):\n",
    "    \"\"\"Function to read the OPPORTUNITY challenge raw data and process all sensor channels\n",
    "    :param data_annotation: string, ['gestures' (default), 'locomotion']\n",
    "        Type of activities to be recognized. The OPPORTUNITY dataset includes several annotations to perform\n",
    "        recognition modes of locomotion/postures and recognition of sporadic gestures.\n",
    "    \"\"\"\n",
    "    full_data = {}\n",
    "    for data_key in ['train', 'val', 'test']:\n",
    "        dic_data={}\n",
    "        data_x = np.empty((0, n_sensors))\n",
    "        data_y = np.empty((0))\n",
    "        print ('Processing dataset files ...')\n",
    "        for filename in files[data_key]:\n",
    "            data = np.loadtxt(filename)\n",
    "            print (f'...{data_key} file {filename}')\n",
    "            x, y = process_dataset_file(data, data_annotation)\n",
    "            data_x = np.vstack((data_x, x))\n",
    "            data_y = np.concatenate([data_y, y])\n",
    "        # Slicing\n",
    "        data_slice_x, data_slice_y = opp_sliding_window(data_x,data_y, window_size, step_size)\n",
    "#         pdb.set_trace()        # Remove nulls\n",
    "        dic_data['samples'] = torch.from_numpy(data_slice_x[data_slice_y!=0])\n",
    "        dic_data['labels'] =  torch.LongTensor(data_slice_y[data_slice_y!=0]-1)\n",
    "        \n",
    "        full_data[data_key] = dic_data\n",
    "        \n",
    "    return full_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded thresholds to define global maximums and minimums for every one of the 113 sensor channels employed in the\n",
    "# OPPORTUNITY challenge\n",
    "NORM_MAX_THRESHOLDS = [3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,   3000,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       3000,   3000,   3000,   10000,  10000,  10000,  1500,   1500,   1500,\n",
    "                       250,    25,     200,    5000,   5000,   5000,   5000,   5000,   5000,\n",
    "                       10000,  10000,  10000,  10000,  10000,  10000,  250,    250,    25,\n",
    "                       200,    5000,   5000,   5000,   5000,   5000,   5000,   10000,  10000,\n",
    "                       10000,  10000,  10000,  10000,  250, ]\n",
    "\n",
    "NORM_MIN_THRESHOLDS = [-3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,  -3000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -3000,  -3000,  -3000,  -10000, -10000, -10000, -1000,  -1000,  -1000,\n",
    "                       -250,   -100,   -200,   -5000,  -5000,  -5000,  -5000,  -5000,  -5000,\n",
    "                       -10000, -10000, -10000, -10000, -10000, -10000, -250,   -250,   -100,\n",
    "                       -200,   -5000,  -5000,  -5000,  -5000,  -5000,  -5000,  -10000, -10000,\n",
    "                       -10000, -10000, -10000, -10000, -250, ]\n",
    "\n",
    "n_sensors = 113\n",
    "# Hardcoded number of classes in the gesture recognition problem\n",
    "n_classes = 4\n",
    "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
    "window_length = 128\n",
    "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
    "step_size = 64\n",
    "label = 'locomotion'\n",
    "\n",
    "full_data ={}\n",
    "for subject_index in [1,2,3,4]:\n",
    "    OPPORTUNITY_DATA_FILES = {'train':[f'dataset/S{subject_index}-Drill.dat',\n",
    "                                      f'dataset/S{subject_index}-ADL1.dat',\n",
    "                                      f'dataset/S{subject_index}-ADL2.dat',\n",
    "                                      f'dataset/S{subject_index}-ADL3.dat'],\n",
    "\n",
    "                              'val':  [f'dataset/S{subject_index}-ADL4.dat'],\n",
    "\n",
    "                              'test':[f'dataset/S{subject_index}-ADL5.dat']\n",
    "                             }\n",
    "    subject_data = generate_data(window_length,step_size, label, OPPORTUNITY_DATA_FILES, n_sensors)\n",
    "    \n",
    "    full_data[f'S_{subject_index}']=subject_data\n",
    "\n",
    "\n",
    "idx_label={1:'a', 2:'b', 3:'c', 4:'d'}\n",
    "for subject_index in [1,2,3,4]:\n",
    "    for data in ['train', 'val', 'test']:\n",
    "        torch.save(full_data[f'S_{subject_index}'][data], f'Opportunity_DA/{data}_{idx_label[subject_index]}.pt')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
